{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate DINOv2 Decoder Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook loads a trained decoder model and a DINOv2 feature extractor to reconstruct images from their DINOv2 latents and visualize the results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoImageProcessor, AutoModel\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm  # Use notebook tqdm\n",
    "import torchvision.transforms.functional as TF\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from workspace.decoder_training import Decoder, LatentImageDataset, get_dinov2_latents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the paths for the image directory, DINOv2 model, trained decoder model, and other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Configuration --- \n",
    "IMAGE_DIR = 'workspace/unsplash_lite_image_dataset/training_images/'  # Image directory\n",
    "DECODER_MODEL_PATH = 'workspace/decoder_model.pth' # Path to the saved decoder weights\n",
    "DINOV2_MODEL_NAME = 'facebook/dinov2-base' # DINOv2 model name\n",
    "DINOV2_CACHE_DIR = 'workspace/dinov2_latents' # Directory to cache DINOv2 latents\n",
    "BATCH_SIZE = 32 # Batch size for latent extraction (adjust based on GPU memory)\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Image Directory: {IMAGE_DIR}\")\n",
    "print(f\"Decoder Model: {DECODER_MODEL_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images, latents, and decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images\n",
    "print(f\"Scanning for images in {IMAGE_DIR}...\")\n",
    "image_paths = list(Path(IMAGE_DIR).glob('*.jpg'))\n",
    "images = [Image.open(path).convert('RGB') for path in image_paths]\n",
    "print(f\"Loaded {len(image_paths)} images.\")\n",
    "\n",
    "# load latents\n",
    "dinov2_latents = torch.load(Path(DINOV2_CACHE_DIR) / 'dinov2_latents.pt')\n",
    "if len(dinov2_latents) != len(image_paths):\n",
    "    print(f\"Error: cached latents don't match image data\")\n",
    "print(f\"Loaded DINOv2 latents from {DINOV2_CACHE_DIR}.\")\n",
    "\n",
    "# load decoder\n",
    "decoder = Decoder().to(DEVICE)\n",
    "decoder.load_state_dict(torch.load(DECODER_MODEL_PATH))\n",
    "decoder.eval()\n",
    "print(f\"Loaded decoder model from {DECODER_MODEL_PATH}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruct Images using the Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_images_tensors = decoder(dinov2_latents.cuda()[:32])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use widgets to select and display original vs. reconstructed image pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have images to display\n",
    "\n",
    "# Create slider widget\n",
    "image_slider = widgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=min(len(images), len(reconstructed_images_tensors)) - 1,\n",
    "    step=1,\n",
    "    description='Image Index:',\n",
    "    continuous_update=False # Only update when slider released\n",
    ")\n",
    "\n",
    "# Output widget to display the plot\n",
    "output_plot = widgets.Output()\n",
    "\n",
    "# Function to update the plot\n",
    "def show_images(index):\n",
    "    with output_plot:\n",
    "        clear_output(wait=True) # Clear previous plot\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "        # --- Original Image ---\n",
    "        original_img = images[index]\n",
    "        # Resize original image to 224x224 for fair comparison (DINO standard size)\n",
    "        original_img_resized = original_img.resize((224, 224))\n",
    "        axes[0].imshow(original_img_resized)\n",
    "        axes[0].set_title(f\"Original Image (Resized)\")\n",
    "        axes[0].axis('off')\n",
    "\n",
    "        # --- Reconstructed Image ---\n",
    "        reconstructed_tensor = reconstructed_images_tensors[index]\n",
    "        # Convert tensor (C, H, W) to PIL Image (H, W, C)\n",
    "        reconstructed_img_pil = reconstructed_tensor.cpu().permute(1, 2, 0).detach().numpy()\n",
    "        axes[1].imshow(reconstructed_img_pil)\n",
    "        axes[1].set_title(f\"Reconstructed Image\")\n",
    "        axes[1].axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Link slider value changes to the update function\n",
    "widgets.interactive(show_images, index=image_slider)\n",
    "\n",
    "# Display the widgets\n",
    "print(\"Use the slider to view different image reconstructions:\")\n",
    "display(image_slider, output_plot)\n",
    "\n",
    "# Initial display\n",
    "show_images(image_slider.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
